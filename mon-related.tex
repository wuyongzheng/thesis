\section{Background and Related Work}

In this chapter, we give some background and related work on system monitoring.

\TODO{define system monitoring}

Related work can be classified in a number of ways.
From the enforcement point of view, we have discretionary and
mandatory monitoring.
Discretionary monitoring requires that the monitored software
actively report to its monitor.
The traditional UNIX \code{syslog} is an example of discretionary monitoring.
A log entry is generated when the monitored software calls \code{syslog(2)}.
The naive \code{printf()} debugging technique is also discretionary monitoring.
In contrast, mandatory monitoring systems enforce that logs entries are always
generated when certain actions are performed by the monitored software.
The \code{ptrace(2)} interface and Solaris Basic Security Module (BSM) Auditing
are examples of mandatory monitoring.
Mandatory monitoring is more suited for security purpose because of its enforcement.
Discretionary monitoring may give more friendly output since the monitored
software knows which pieces are more important.

A correlated classification is transparent/opaque monitoring.
In transparent monitoring, the monitored software does not need to be adapted
and sometimes is not aware of being monitored;
whereas in opaque monitoring, the monitored software need to be either
rewritten and recompiled or transformed manually.
The two types of classification are usually correlated because transparent monitoring
is usually mandatory as well, and opaque monitoring is usually discretionary.

 From execution environment point of view, the monitor can be executed
in a number of environments.
\begin{itemize}
\item The monitor can be executed in the process (i.e. same address)
of the monitored software.
The naive \code{printf()} debugging technique belong to this category.
A common technique to monitor API or DLL function calls is to rewrite
the to-be-monitored function with a wrapper function which does the
logging and then calls the actual function.
This type of monitor is usually used for debugging purpose, and not for
security, because the monitoring can be circumvented.
\item In order to prevent circumvention,
the monitor can be executed in the kernel (assuming the kernel is authentic).
The \code{strace} utility uses the kernel \code{ptrace(2)} interface
to monitor system calls.
Most of the related work that we are going to introduce are kernel based.
\item In the same vein, to security monitor kernel events, the monitor
should execute in a lower level than the kernel, i.e. the hypervisor.
Examples are the virtual machine monitors.
\item To get instruction level monitoring, the {\em instrumentation}
technique is used.
There are a number of instrumentation methods.
The earliest instrumentation execute binary program in a similar way
like interpretation language.
\TODO{...}
\end{itemize}

A monitoring system can have side effects to alter the execution of the
monitored software or no side effects (except maybe performance overhead).
An example of the former is \code{ptrace(2)} which can be used to filter
system calls.
Examples of the later include Solaris BSM and DTrace.

\subsection{Traditional \code{syslog}}

Syslog is the main logging tool on a UNIX systems. It centrally manages logging
for your main system services. Syslog is discretionary in such a sense that it
requires the program to actively call the \code{syslog(2)} system call in order to
generate a log message. Syslog is implemented in two halves. One half is a set
of standard C-library routines. Programs utilize these routines to send
messages to the log daemon. The other is a daemon process \code{syslogd}. It is
configured with the \path{/etc/syslog.conf} file. It writes log messages to various
locations.

When writing kernel code, one can send log messages to \code{syslog} by calling
\code{printk}\footnote{\code{printk} is Linux kernel specific} kernel.  This is
realized through \code{klogd}, the kernel log daemon.  \code{klogd} is a system
daemon which intercepts and logs Linux kernel messages. It is usually
configured to forward kernel messages to \code{syslogd}. Traditional logging
mechanism such as \code{syslog} is discretionary in nature, thus cannot be used
for security purpose. In the security monitoring context, we should not trust
the monitored program, thus the log message supplied by it should also not be
trusted. For example, the application does not log or logs something to spoof
the monitor.

\subsection{\code{ptrace} and \code{/proc}}
\label{sec:ptrace}

A commonly used technique for monitoring is system call tracing or system call
interposition to monitor the system calls made by a process.
For portability, systems like Janus \cite{wagner1999janus} or Alcatraz \cite{liang2009alcatraz}
use the Unix user-level mechanisms \code{ptrace} or \code{/proc} to do
system call tracing.
This usage is problematic because it is not
meant to be a secure monitoring mechanism, e.g.
\code{ptrace} was meant to support debuggers.
In the Solaris manual pages, \code{ptrace} is described as being
``unique and arcane''.
These kinds of problems and common
pitfalls with user-level system call interposition
are discussed in \cite{garfinkel2003traps}, such as:
(i) race conditions between time of check and time of use (TOCTOU), 
i.e. a buffer can be modified by another thread;
(ii) non-inheritance of tracing, i.e. special \code{strace} hacks in Linux;
and (iii) not transparent with respect to setuid/setgid executables 
and signals,
i.e. \code{ptrace} and \code{/proc} disable tracing 
on setuid/setgid executables.  
One could write a simple C program as in Figure~\ref{fig:ptrace-bug}
to escape from ptraceing.
After several iterations, some
child processes will not be traced by the tracing program.
As well as \code{ptrace(2)}, \code{/proc}
brings side-effect to the traced process.
When a traced process calls \code{setuid(2)},
the call will fail because the tracing process would have insufficient
privileges to the setuided process.
Because of their subtleties and intrinsic difficulties,
\code{ptrace} and \code{/proc} are not suitable for general purpose user-level
monitoring although they may be useful in specific situations.

\begin{figure}[htb]
\begin{verbatim}
#include <sys/types.h>
#include <sys/times.h>
#include <unistd.h>
main()
{
  struct tms timing;
  int i;
  getpid();
  if (fork() == 0) {
    getppid();
    if (fork() == 0) {
      times(&timing);
      _exit(1);
    }
    for (i=0; i < 10; getpid()) ;
  }
}
\end{verbatim}
\caption{Simple C program to escape \code{ptrace}}
\label{fig:ptrace-bug}
\end{figure}

The other serious drawback of \code{ptrace} or \code{/proc} is that
the overhead is considerable, incurring at least two
context switches per traced system call.
Our micro benchmarks in \TODO{fill} show that this can lead to an order of magnitude
slowdown on system call intensive programs.

\subsection{Light-weight Auditing Framework}

The lightweight auditing framework is intended to be a way for the kernel to
get various types of audit information out to user space without slowing things
down, especially when auditing is not being used. The framework is meant to
serve as a complement to SELinux; it is already being shipped as a part of the
Fedora Core 2 test 2 kernel. There are two kernel-side components to the audit
code. The first is a generic mechanism for creating audit records and
communicating with user space. All of that communication is performed via
netlink sockets; there are no new system calls added as part of the audit
framework. Essentially, a user-space process creates a NETLINK AUDIT socket,
writes audit request structures it, and reads back audit reply structures in
return. The generic part of the audit mechanism can control whether auditing is
enabled at all, perform rate limiting of messages, and handle a few other
tasks. On the kernel side, it provides a printk()-like mechanism for sending
messages to user space. This code also implements a user-specified policy on
what happens if memory is not available for auditing; truly paranoid
administrators can request that the kernel panic in such situations.

\subsection{Linux Trace Toolkit (LTT) and LTTng}
 
\subsection{Windows Sysinternals}
\label{sec:sysinternals}

FileMon \cite{filemon} and RegMon \cite{regmon}
are file and registry monitoring tools for Windows, respectively.
They monitor operations taking place on
the registry or specified file system.
A graphical interface is used to filter and display monitored events in real time.
We have observed (details in Section \TODO{fill}) that both tools can drop events when the
events are fast generated.

\subsection{Solaris DTrace}
\label{sec:dtrace}

DTrace\cite{cantrill2004dynamic} is a dynamic tracing framework
created on Solaris 10, for troubleshooting kernel and application problems
on production systems.
It allows almost all aspects of the kernel to
be instrumented, with 30,000 \TODO{recheck} probes\footnote{
Since DTrace is in active development, our information on DTrace
is based on its current status in June 2011.
} in the kernel.
It uses a scripting language, D programs,
which are run within the kernel to do monitoring.
DTrace is very powerful because
they run within the kernel and also because of the large number of
instrumented probes.
In-kernel also means that DTrace can be efficient.\footnote{
However, our micro-benchmarks in Section \TODO{fill} indicate that while it is significantly
faster than \code{proc}, we have observed a factor of 2x slowdown.
}
To ensure safety of running in the kernel, DTrace programs
are restricted and checked for safety.
However, we believe that it is far safer to run monitors in user mode.

\subsection{KProbes, DProbes and SystemTap}
\label{sec:systemtap}

\subsection{Instrumentation tool: Pin, valgrind and DynamoRIO}
\label{sec:instrumentation}
